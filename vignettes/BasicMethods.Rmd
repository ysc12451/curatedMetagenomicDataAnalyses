---
title: "BasicMethods"
output: html_document
date: "2023-08-31"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load required libraries
library(dplyr)      # For data manipulation
library(caret)      # For data preprocessing
library(FactoMineR) # For PCA
library(glmnet)     # For logistic regression
library(reticulate)
use_python("D:/Anaconda/Anaconda3/python.exe")

data_file_path = "D:/OneDrive/OneDrive - UW-Madison/Kris/Code/curatedMetagenomicDataAnalyses/vignettes/"
```


```{r}
crc_whole <- read.csv(paste0(data_file_path, "crc_whole_taxon.csv"))
# crc_sepa <- read.csv(paste0(data_file_path, "crc_separate_taxon.csv"))
crc_meta <- read.csv(paste0(data_file_path, "crc_meta.csv"))
study_names <- unique(crc_whole[,2])
study_nobs <- c(154,60,81,80,60,80,104,125,616,128,156)

# remove NA in the response
rows_with_na <- which(!complete.cases(crc_whole[,3])) #
crc_whole <- crc_whole[-rows_with_na, ]
crc_meta <- crc_meta[-rows_with_na, ]

# temperally set NA in the count matrix as 0
crc_whole[is.na(crc_whole)] <- 0

colnames(crc_whole) <- gsub("__", "-", colnames(crc_whole))
colnames(crc_whole) <- gsub("_", "-", colnames(crc_whole))

print(paste(nrow(crc_whole), 'observations, ', ncol(crc_whole)-3, 'species'))
```

```{r}
# PCA
pca_result <- PCA(features, scale.unit = TRUE)
```

```{python}
import numpy as np
import pandas as pd
import scipy.sparse as sp
import matplotlib.pyplot as pl

import sklearn as sk
import pandas as pd
import numpy as np
import pathlib as pl

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from scipy.stats import pearsonr
from sklearn.metrics import mean_squared_error as mse
from sklearn.metrics import zero_one_loss, accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
from collections import Counter

import os
import sys
os.chdir("D:\OneDrive\OneDrive - UW-Madison\Kris\Code\curatedMetagenomicDataAnalyses\\vignettes")
# os.chdir("C:\OneDrive\OneDrive - UW-Madison\Kris\Code\curatedMetagenomicDataAnalyses\\vignettes")
import gc

# visualizations
import plotly.express as px
import plotly.offline as pyo
import plotly
import plotly.graph_objs as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt

custom_colors = ["#a8e6cf","#dcedc1","#ffd3b6","#ffaaa5","#ff8b94"]
palette = sns.set_palette(sns.color_palette(custom_colors))
FP_CRC_META = os.path.join("crc_meta.csv")
FP_CRC_SEPARATE = os.path.join("crc_separate_taxon.csv")
FP_CRC_WHOLE = os.path.join("crc_whole_taxon.csv")
FP_CRC_MAT = os.path.join("crc_mat.csv")
```

```{python}
crc_meta = pd.read_csv(FP_CRC_META)
# crc_sepa = pd.read_csv(FP_CRC_SEPARATE)
crc_whole = pd.read_csv(FP_CRC_WHOLE)
crc_whole = crc_whole.fillna(0)
# crc_data = crc_sepa.iloc[7:, 3:]
# crc_data = crc_data.astype(float)

# crc_sepa.rename(columns={'Unnamed: 0': 'observations'}, inplace=True)
study_names = np.unique(crc_whole.study_name)
```

```{python}
response_mask = crc_whole.iloc[:,2].isin([0, 'carcinoma_surgery_history'])

# Apply the mask to the DataFrame to keep rows that don't match the categories
crc_whole = crc_whole[~response_mask]

y_mapping = {
    "control": 0,
    "CRC": 1,
    "adenoma": 2
}

crc_whole.iloc[:,2] = [y_mapping[item] for item in crc_whole.iloc[:,2]]
```
```{python}
# Number of observations per study
Counter(crc_whole.iloc[:,1])
```
```{python}
# Number of observations per study
Counter(crc_whole.iloc[:,2])
```
```{python}
study_test = [study_names[1]]
study_train = [study for study in study_names if study not in study_test]
print(study_test)
print(study_train)
```

```{python}
data_train = crc_whole[crc_whole['study_name'].isin(study_train)]
data_test = crc_whole[crc_whole['study_name'].isin(study_test)]
X_train = data_train.iloc[:, 3:].values
X_test = data_test.iloc[:, 3:].values
# y_train = data_train.iloc[:, 2] == "CRC"
# y_test = data_test.iloc[:, 2] == "CRC"
y_train = data_train.iloc[:, 2]
y_test = data_test.iloc[:, 2]

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

Counter(y_test)
```

```{python}
# Run PCA
p = 100

X_train_sd = StandardScaler().fit_transform(X_train)
pca_train = PCA(n_components=p)
X_train_pca = pca_train.fit_transform(X_train_sd)
```


```{python}
# Basic methods
model = LogisticRegression(multi_class='multinomial')
# model = RandomForestClassifier()
# model = KNeighborsClassifier()
model.fit(X_train_pca, y_train)

X_test_sd = StandardScaler().fit_transform(X_test)
X_test_pca = pca_train.transform(X_test_sd)
y_pred = model.predict(X_test_pca)
```
```{python}
class_report = classification_report(y_test, y_pred)
print("LogisticRegression Report:\n", class_report)
```

```{python}
conf_matrix = confusion_matrix(y_test, y_pred)
# df_conf_matrix = pd.DataFrame(conf_matrix, index=['True 0', 'True 1'], columns=['Predicted 0', 'Predicted 1'])
df_conf_matrix = pd.DataFrame(conf_matrix, index=['True 0', 'True 1', 'True 2'], columns=['Predicted 0', 'Predicted 1', 'Predicted 2'])
print(df_conf_matrix)
```

